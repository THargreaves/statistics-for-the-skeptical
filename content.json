{"pages":[{"title":"","path":"about/index.html","permalink":"https://www.statisticsfortheskeptical.com/about/index.html","content":"<p>Hi, I’m <a href=\"https://www.linkedin.com/in/tim-hargreaves/\" target=\"_blank\" rel=\"noopener\">Tim</a>. I am an undergraduate Mathematics and Statistics student working as a data scientist at the pharmaceutical company AstraZeneca. My key focuses include effective visualisation, non-parametric statistical methods, and interpretable machine learning.</p><p>‘Statistics for the Skeptical’ was born out my frustration towards the blatant disrespect for statistics that many news and media outlets demonstrate in the modern, attention-hungry ecosystem, and the impacts of such foul-play on public trust and understanding. I was tipped over the edge when my commute was spoiled by the Radio 4 morning news featuring deceptive statistics relating to supposed changes in the rate of violent crime in the UK. This led me to produce <a href=\"https://github.com/THargreaves/statistics-for-the-skeptical-wids\" target=\"_blank\" rel=\"noopener\">a talk</a> for the Warwick International Development Society in which I dissected this and many other examples of poor statistical thinking that often come up in our daily lives.</p><p>This blog is a continuation of this project. Each post tackles a statistical fallacy, focusing on a real-world example that I have come across in my life, and how one can avoid falling for these tricks in the future. I hope you enjoy the series and learn some useful reasoning skills in the process.</p><p>Thanks for reading and, most importantly, <strong>stay skeptical</strong>.</p>"}],"posts":[{"title":"Goodhart's Law","path":"goodharts_law/","permalink":"https://www.statisticsfortheskeptical.com/goodharts_law/","content":"<p><em>This blog post is a lightly modified transcription of a segment I wrote for <a href=\"https://www.wdss.io/\" target=\"_blank\" rel=\"noopener\">Warwick Data Science Society</a>‘s podcast, <a href=\"http://podcast.wdss.io/\" target=\"_blank\" rel=\"noopener\">DataBasic</a>. The original episode can be found on <a href=\"https://youtu.be/aiKkLg-0vMc?t=321\" target=\"_blank\" rel=\"noopener\">YouTube</a>, or other platforms via the podcast’s <a href=\"http://podcast.wdss.io/\" target=\"_blank\" rel=\"noopener\">landing page</a>.</em></p><hr><p>Let me tell you a story about a man and his dog. And just trust me, this does have something to do with statistics.</p><p>It takes place in Paris, 1908, alongside the banks of the river Seine. One day, the stillness of the winter air was broken by the cries of a small child, having fallen into the waters after playing on the riverside. With few around, the child was at serious risk of drowning; that is, if it wasn’t for a brave Newfoundland dog, that bounded into the icy stream to rescue this helpless victim.</p><p>Naturally, once the owner discovered his dog’s heroic efforts, he petted him, praised him, and finally presented him with a succulent slice of steak. You might think that this is where the story ends, but no. Just two days later, another child—also playing alongside the Seine—fell victim to a similar feat. Don’t fear though, because the same dog proudly saved the child by dragging it to the shore, to be praised just the same as before.</p><p>At this point, the neighbourhood was undoubtedly curious. Was there a series child-abuser in the area, pushing any unsuspecting child into the frozen current? It wasn’t too long until an answer to this question was found. Yes, there was a serial offender. And his games soon stopped once he was caught red-handed. Or perhaps I should say, red-pawed.</p><p>You heard that right; this clever dog had made a discovery. If—whenever it saw a child playing near the river—it were to knock the child in, just to immediately pull them back out, he would have established himself a near infinite supply of steak. That is, until he was caught in the act, and the stream of treats promptly ran dry.</p><p><img src=\"/resources/goodharts-law/nyt.png\" alt=\"\"></p><center><i>The original <a href=\"https://timesmachine.nytimes.com/timesmachine/1908/02/02/104716889.html\" target=\"_blank\" rel=\"noopener\">New York Times article</a> detailing the occurance</i></center><p>What can we learn from this tale, and how it help us in our practice of statistics?</p><p>This anecdote is an example of Goodhart’s Law: When a measure becomes a target, it ceases to be a good measure. In this case, our measure for success was the dog pulling a child out of the river. The problem is, by focusing too closely on this as our target, the dog quickly learned that it could cheat the system by pushing in the children itself.</p><p>Goodhart’s law appears everywhere.</p><p>When Soviet factories were given targets based on the number of nails they produced, the nails shrunk in size to the point of becoming useless. When weight became the new target, they grew to comical proportions.</p><img src=\"/resources/goodharts-law/nails.jpg\" style=\"max-width:200px\"><center><i>A famous Soviet cartoon mockingly portraying an exagerated version of this tale</i></center><p>Or how about in India, when the government offered money for each dead cobra that was turned in, in an attempt to reduce the abundance of loose cobra snakes? Much to the governments disdain, citizens started breeding their own cobras to game the system. Once the government became wise to this and ended the scheme, these were then released out into the wild, making the problem far worse than it was in the beginning.</p><p>There are also many examples of Goodhart’s Law that appear when building statistical models for prediction. It’s easy to obsess of the accuracy of a model, forgetting to consider how such accuracy was attained. Perhaps your dataset was unbalanced and your model has learnt to bias its answers towards one class. For example, when trying to predict whether patients have a rare disease, guessing ‘no’ for everyone will always give rise to high accuracy.</p><p><img src=\"/resources/goodharts-law/illness.svg\" alt=\"\"></p><center><i>An image extract from an old <a href=\"https://www.ttested.com/inaccuracy-of-accuracy/\" target=\"_blank\" rel=\"noopener\">post</a> on my main blog <a href=\"https://www.ttested.com/\" target=\"_blank\" rel=\"noopener\">T-Tested</a> discussing the limitations of using accuracy to measure model performance in more detail</i></center><p>Even worse, perhaps your dataset is not representative of the real world. A classic example is that of ALVINN, a self-driving car from the late 80s. Its performance was incredible…until it reached a bridge, at which point it lurched round so dangerously, with motions so manic, that the researchers had to take control. What went wrong? Later model inspection revealed that ALVINN actually wasn’t that good at driving, but rather had learnt that if it kept the grassy verge on the side of the road to its left, it was doing just fine. This worked great until a bridge approached, and the verge disappeared, leading to chaos.</p><p><img src=\"/resources/goodharts-law/alvinn.jpg\" alt=\"\"></p><center><i>ALVINN—not quite as sleak as Tesla but certainly as flashy</i></center><p>So, how do we come up with an ungameable metric? One that is robust to Goodhart’s law? The answer is: we don’t. Instead, we use a combination of metrics, heuristics, and carefully and thoughtful analysis of our model to try to understand how and why it came to its decisions. And most importantly, if we keep Goodhart’s law at the front of our mind, we are much less likely to fall for it in the future.</p><p>Either way, stay skeptical.</p>"},{"title":"Survivorship Bias","path":"survivorship_bias/","permalink":"https://www.statisticsfortheskeptical.com/survivorship_bias/","content":"<h2 id=\"They-Just-Don’t-Make-‘em-Like-They-Used-To\"><a href=\"#They-Just-Don’t-Make-‘em-Like-They-Used-To\" class=\"headerlink\" title=\"They Just Don’t Make ‘em Like They Used To\"></a>They Just Don’t Make ‘em Like They Used To</h2><p>Last week, I found myself chatting to a fellow guitarist. As musicians go, guitarists are perhaps some of the most gear-obsessed. It was therefore unsurprising that this was where the conversation naturally led. In particular, we were soon talking about the guitars we own and play; my acquaintance preferring the older, vintage varieties. His reasoning for this preference was quite straightforward—“they just don’t make ‘em like they used to”.</p><p>He went on to claim that because of mechanisation and automation in modern guitar manufacturing, you’d be better off buying a relic from the 60s or 70s when things were done “the proper way”, than spending your money on a contemporary model. This is actually not an assertion I wish to dispute; indeed, I have bought many aged second-hand guitars, and they have all been great. Instead, I want to apply some skepticism to the reasoning behind this claim—the assumption that automation has led to a regression in the quality of guitar manufacturing. This may seem paradoxical—how can it be the case that I both agree with the purchase of old guitars over new yet dispute that they were made any better than their modern counterparts? The answer lies in a statistical misconception known as <em>Survivorship Bias</em>.</p><h2 id=\"I-Will-Survive\"><a href=\"#I-Will-Survive\" class=\"headerlink\" title=\"I Will Survive\"></a>I Will Survive</h2><p>Survivorship bias is a statistical fallacy that regularly finds its ways into everyday conversation. It arises when we neglect to consider failures, focusing instead mainly on successes. This is an easy trap to fall into. After all, it would be unlikely that any failures would remain in the world for excessively long periods of time as the very nature of their failure makes them undesirable. Consider as an example two buildings erected on the same date in the distant past—one elegant and majestic; the other disfigured and repugnant. It should come as no surprise that the former would be more likely to survive the test of time, the latter liable to eventually be torn down and exchanged for a more tasteful replacement. It follows that when we look back on the historic buildings of a city, we are more likely see examples demonstrating greater beauty. This would give the impression that older buildings were constructed to a higher aesthetic standard than their modern counterparts. To some extent, this may be true, but it is certainly not the whole story.</p><p>The same holds true for the guitar example. Even if the production quality of guitars was unchanged throughout time, any high quality relic would be likely to last a lot longer than a low quality adversary. There are many factors that contribute to this. For example, high quality guitars are likely to:</p><ul><li>last longer simply because they are of high quality</li><li>be looked after with greater care</li><li>have greater sentimental value (and so be less likely to be disposed of or given away)</li></ul><p>Whatever the underlying mechanism may be, the increased likelihood of survival for high quality guitars is undeniable. This leads to the appearance that older guitars are better made. If we don’t want to fall for survivorship bias, however, we’ll have to apply some skepticism and dig a bit further before we can jump to a conclusion. For example, we could look at an old guitar catalogue to see whether the examples we have today are truly representative of the larger historic population.</p><h2 id=\"Survivorship-Bias-in-Action\"><a href=\"#Survivorship-Bias-in-Action\" class=\"headerlink\" title=\"Survivorship Bias in Action\"></a>Survivorship Bias in Action</h2><p>To really drive my point home, I have created a short animation to showcase survivorship bias at work. For each year from 1960 to 2020, I have simulated the annual production of around 25 guitars. The initial quality of the guitars follows the same arbitrary distribution for each year (i.e. older guitars are neither better nor worse). As time progresses (marked by the vertical black line), the areas of the points shrink to zero at a rate dependent on their initial quality. This represents their deterioration and eventual destruction. After the simulation has made it to 2020 an interesting pattern emerges. Although each guitar was originally generated so that their quality was independent of the year of manufacturing, the final graph makes it <em>look</em> like older guitars have a generally higher quality. This is not the case though, it is simply survivorship bias trying to fool us.</p><video controls><source src=\"/resources/survivorship-bias/survivorship_bias_animation.mp4\" type=\"video/mp4\">Your browser does not support the video tag.</video><p><center><i>The source code for this animation can be found <a href=\"https://github.com/THargreaves/statisticsfortheskeptical/resources/survivorship-bias/survivorship-bias-animation.R\" target=\"_blank\" rel=\"noopener\">here</a></i></center></p><p>Once you’re aware of survivorship bias, you’ll start to notice it everywhere. Another musical instance of the fallacy arises when people claim that modern pop music isn’t as well-written as that of previous decades. Although there is <a href=\"https://playback.fm/blog/science-proved-music-getting-worse\" target=\"_blank\" rel=\"noopener\">some evidence</a> to suggest that modern pop music is simpler than it was in the past, the true difference is likely to be far less than we perceive. After all, it’s difficult to forget the lyrical poetic-panoply and sonic-splendor that is Queen’s ‘Bohemian Rhapsody’; this is less so the case for George Elrick’s 1936 release ‘I Like Bananas Because They Have No Bones’.</p><p><img src=\"/resources/survivorship-bias/cover_arts.png\" alt=\"\"></p><center><i>I joke, but 'I Like Bananas Because They Have No Bones' is a surprisingly good song</i></center><h2 id=\"Stats-Saves-Lives\"><a href=\"#Stats-Saves-Lives\" class=\"headerlink\" title=\"Stats Saves Lives\"></a>Stats Saves Lives</h2><p>Survivorship bias is not only important for bringing some sense of reality to ‘<a href=\"http://www.genfkd.org/not-born-wrong-generation\" target=\"_blank\" rel=\"noopener\">the wrong generation</a>‘ crowd. At times, it can be the difference between life and death.</p><p>One classic example occured during World War II. It concerned an analysis that was performed on damaged aircraft returning from missions. The analysis discovered that the areas of the plane marked in red in the image below were the most likely to return laced with bullet holes.</p><p><img src=\"/resources/survivorship-bias/plane_shots.png\" alt=\"\"></p><p><center><i>Image credit: <a href=\"https://commons.wikimedia.org/wiki/File:Survivorship-bias.png\" target=\"_blank\" rel=\"noopener\">Wikimedia Commons</a></i></center></p><p>The researchers concluded that the best course of action was to apply more armour to these regions. This was until statistician <a href=\"https://en.wikipedia.org/wiki/Abraham_Wald\" target=\"_blank\" rel=\"noopener\">Abraham Wald</a> pointed out that the study had only considered aircraft that had made it back, neglecting any that didn’t. This is the exact description of survivorship bias—the army researchers only considered the ‘successes’ (planes that returned) and not the ‘failures’ (those shot down by the enemy). Ward instead proposed that the best place to position the new armour was everywhere <em>but</em> the areas of frequent damage. This becomes clearer when we consider that World War II aircraft weapons weren’t exactly precision instruments and so bullet holes could be assumed to be distributed uniformly. Despite this, only planes with bullet holes in certain places were returning, suggesting that any damage to other areas of the fuselage were likely fatal.</p><p>A similar example from World War I arose with the introduction of the Brodie helmet. This led to a dramatic increase in the frequency of admissions to the field hospital for severe head injuries. This almost led to a complete withdrawal of the helmet. That was until a watchful statistician applied some skeptism and reminded army command that a head injury is highly preferable to death (which may have been the conclusion of an incident before the introduction of the helmet)</p><h2 id=\"Closing-Thoughts\"><a href=\"#Closing-Thoughts\" class=\"headerlink\" title=\"Closing Thoughts\"></a>Closing Thoughts</h2><p>I hope, now that you’ve seen a few examples of survivorship bias and its potentially severe consequences, you will be equipped to avoid falling for this fallacy when it next arises in life. But to help you avoid these misconceptions, there are a few red flags to watch out for that often indicate survivorship bias might be at play:</p><ul><li>Comparisons are made to the past, and specifically how it was better (e.g. guitars/pop music)</li><li>Observations are being made about a person/object that relate to its destruction (e.g. bullet holes and helmets)</li><li>Only the most notable examples of a group are being considered (e.g. historic architecture)</li></ul><p>With these key ideas in mind, I would like to leave you with one final example to ponder. It is not difficult to find many high school dropouts that went on to be wildly successful. To name a few, Richard Branson, Quentin Tarantino, and Aretha Franklin all left school before reaching the age of sixteen. If we look at college dropouts, the search becomes even easier (the tech-trio Mark Zuckerburg, Bill Gates, and Steve Jobs for example). This is occasionally used by people to argue against the importance of tertiary and higher education. After all, if such successful people dropped out of their studies, it must be a good idea, right? Hopefully some skeptism and awareness of survivorship bias can help you poke some holes in this theory.</p><p>Finally, if you come across any examples of survivorship bias or can think of your own, please do share them in the discussion below.</p><p>Either way, stay skeptical.</p>"}],"categories":[],"tags":[]}